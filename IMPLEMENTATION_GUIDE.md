# SentinelCore Stability Fix - Implementation Guide

**Status**: Database instability identified and fixed  
**Root Cause**: Connection pool too small (5 connections) with 5 concurrent workers  
**Severity**: üî¥ CRITICAL - Causes timeouts and system unresponsiveness  

---

## Quick Summary

Your system is experiencing **connection pool exhaustion**:

```
‚îå‚îÄ 5 Background Workers (each need 1+ connections)
‚îú‚îÄ HTTP API requests (each need 1 connection)
‚îú‚îÄ Pool Size: 5 connections
‚îî‚îÄ Result: EVERYONE IS WAITING FOR A CONNECTION
```

This causes:
- ‚ùå HTTP timeouts (504 Gateway Timeout)
- ‚ùå API errors (connection refused)
- ‚ùå Database appears unresponsive
- ‚ùå Swap memory usage (system slows down dramatically)

---

## Step 1: Apply Code Changes (DONE ‚úì)

### What was changed:

1. **`vulnerability-manager/config/default.yaml`**
   - Pool size: `5` ‚Üí `30` ‚úì
   - Added connection timeout: `10s` ‚úì
   - Added statement timeout: `30s` ‚úì

2. **`vulnerability-manager/src/main.rs`**
   - Added `acquire_timeout(10s)` - wait max 10s for available connection ‚úì
   - Added `idle_timeout(600s)` - close connections after 10 min idle ‚úì
   - Added `max_lifetime(1800s)` - refresh connections every 30 min ‚úì

3. **`vulnerability-manager/.env.example`**
   - Created template for environment-based configuration ‚úì

---

## Step 2: Recompile Backend

```bash
cd vulnerability-manager

# Clean build
cargo clean

# Rebuild with new configuration
cargo build --release

# Time: ~3-5 minutes on modern hardware
```

If compilation succeeds, you'll see:
```
   Compiling vulnerability-manager v0.1.0
    Finished release [optimized] target(s) in 234.23s
```

---

## Step 3: Configure Environment Variables (Recommended)

Create `.env` file in `vulnerability-manager/` directory:

```bash
cd vulnerability-manager
cp .env.example .env
nano .env  # Or use your editor
```

Update these critical values:

```bash
# Must match your PostgreSQL setup
DATABASE_URL=postgresql://vlnman:DogNET@localhost:5432/vulnerability_manager

# Change from hardcoded value
SERVER_PORT=8080

# Set strong JWT secret (generate new one)
JWT_SECRET=$(openssl rand -base64 32)
```

---

## Step 4: Optimize PostgreSQL (Optional but Recommended)

### Option A: Automated Optimization (Recommended for most)

```bash
# This script calculates optimal settings based on your hardware
sudo bash optimize_postgresql.sh

# What it does:
# - Calculates shared_buffers based on available RAM
# - Enables slow query logging (queries > 1 second)
# - Configures autovacuum for regular maintenance
# - Adds connection timeouts
# - Restarts PostgreSQL service
```

### Option B: Manual Optimization

Edit `/etc/postgresql/15/main/postgresql.conf`:

```bash
sudo nano /etc/postgresql/15/main/postgresql.conf
```

Add at the end:

```ini
# Connection Pool
max_connections = 50

# Memory (adjust based on your RAM - assuming 16GB)
shared_buffers = 4GB
effective_cache_size = 8GB
work_mem = 50MB
maintenance_work_mem = 1GB

# Logging
log_min_duration_statement = 1000
log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h '

# Autovacuum (maintenance)
autovacuum = on
autovacuum_naptime = 10s

# Timeouts
idle_in_transaction_session_timeout = '10min'
statement_timeout = '5min'
```

Then restart:

```bash
sudo systemctl restart postgresql
```

---

## Step 5: Verify Configuration

### Check connection pool is working:

```bash
cd vulnerability-manager
cargo run --release &

# In another terminal, after ~5 seconds:
curl http://localhost:8080/api/health | jq .
```

Expected output:
```json
{
  "status": "ok",
  "database": "connected",
  "pool_idle": 28,
  "pool_max": 30,
  "pool_utilization": 6
}
```

‚úì If `pool_utilization` is < 50%, you're good!  
‚ùå If `pool_utilization` is > 80%, pool is still undersized.

---

## Step 6: Run Diagnostic Tests

### Test 1: System Diagnosis

```bash
# Check database health
bash debug_database.sh

# Output will show:
# - Active connections
# - Table sizes
# - Unused indexes
# - Optimization opportunities
```

### Test 2: Performance Benchmark

```bash
# Benchmark connection pool under load
bash test_performance.sh

# Output will show:
# - Sequential request latency
# - Concurrent request success rate
# - Throughput (requests/sec)

# Expected improvements:
# Before fix: 95-105ms latency, 90-95% success
# After fix: 50-80ms latency, 99.9%+ success
```

### Test 3: Memory Usage

```bash
# Monitor during load test
watch -n 1 'free -h && echo "---" && ps aux | grep "vulnerability-manager\|postgres"'

# Should see:
# - SWAP usage decreasing (was 1.8GB, should be < 100MB)
# - PostgreSQL memory stable (not growing)
# - Fewer context switches
```

---

## Step 7: Monitor for 24-48 Hours

After applying fixes, monitor for stability:

```bash
# Watch logs for errors
journalctl -u sentinelcore -f

# Or if using docker:
docker logs -f <container_name>

# Check for:
# ‚ùå Connection timeout errors
# ‚ùå Database connection refused
# ‚ùå Slow query warnings
# ‚úì Normal operation logs
```

---

## Expected Results

### Before Fix
```
Pool Utilization: 100% (always saturated)
Latency: 5-30s (blocking on connections)
Success Rate: 90-95% (timeouts)
Swap Usage: 1.8GB (causing slowness)
```

### After Fix (30 connections + PostgreSQL tuning)
```
Pool Utilization: 20-40% (healthy)
Latency: 100-500ms (responsive)
Success Rate: 99.9%+ (stable)
Swap Usage: < 100MB (fast operation)
```

---

## Troubleshooting

### Compilation Errors

```bash
# If you get SQLx errors during compilation:
cd vulnerability-manager
cargo clean

# Regenerate SQLx cache
SQLX_OFFLINE=true cargo build --release
```

### PostgreSQL Won't Start After Optimization

```bash
# Restore from backup
sudo cp /etc/postgresql/15/main/postgresql.conf.backup.* \
        /etc/postgresql/15/main/postgresql.conf

sudo systemctl restart postgresql
```

### Still Getting Connection Timeouts

```bash
# Check if max_connections was actually increased
psql -U vlnman -d vulnerability_manager -c "SHOW max_connections;"

# Should return: 50 (or your new value)

# Check active connections
psql -U vlnman -d vulnerability_manager -c \
  "SELECT count(*) FROM pg_stat_activity;"

# Check pool configuration
curl http://localhost:8080/api/health | jq '.pool_*'
```

### Memory Still High

```bash
# Stop frontend dev server (uses 1.5GB)
pkill -f "react-scripts start"

# If running in Docker, limit memory:
docker run --memory="2g" --memory-reservation="1.5g" <image>

# Check which process uses the most memory:
ps aux | sort -k4 -rn | head -10
```

---

## Files Created/Modified

### Modified Files
- ‚úì `vulnerability-manager/config/default.yaml` - Increased pool size
- ‚úì `vulnerability-manager/src/main.rs` - Added timeouts and logging

### New Files
- ‚úì `vulnerability-manager/.env.example` - Configuration template
- ‚úì `DIAGNOSIS_AND_BENCHMARKS.md` - Full analysis report
- ‚úì `debug_database.sh` - Database diagnostic tool
- ‚úì `test_performance.sh` - Performance benchmark suite
- ‚úì `optimize_postgresql.sh` - PostgreSQL tuning script
- ‚úì `IMPLEMENTATION_GUIDE.md` - This file

---

## Next Steps for Feature Development

Now that stability is fixed, consider:

1. **Add per-user rate limiting** (currently only per-IP)
   - Effort: 1-2 days
   - Impact: Prevent user-based DoS

2. **Container scanning** (Trivy, Grype)
   - Effort: 2-3 weeks
   - Impact: Support Docker/Kubernetes scanning

3. **ML false positive detection**
   - Effort: 6-8 weeks
   - Impact: Reduce noise in vulnerability lists

4. **WebSocket real-time updates**
   - Effort: 2 weeks
   - Impact: Live dashboard updates (no refresh)

5. **Advanced caching layer** (Redis)
   - Effort: 1-2 weeks
   - Impact: Faster dashboard, less DB load

---

## Support & Questions

If issues persist after applying these fixes:

1. Check `DIAGNOSIS_AND_BENCHMARKS.md` for detailed analysis
2. Run `debug_database.sh` to diagnose database state
3. Review PostgreSQL logs: `sudo journalctl -u postgresql -f`
4. Check backend logs: `journalctl -u sentinelcore -f`

---

**Last Updated**: 2025-12-15  
**Status**: Ready for Implementation  
**Estimated Time**: 15-30 minutes
