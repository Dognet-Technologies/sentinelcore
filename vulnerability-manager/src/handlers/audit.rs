// src/handlers/audit.rs
// FIXED: Aggiunti cast INET e corretti campi struct per PostgreSQL

use axum::{
    extract::{Path, Query, Extension},
    http::StatusCode,
    Json,
};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use sqlx::PgPool;
use std::sync::Arc;
use uuid::Uuid;

use crate::auth::Claims;
use crate::models::user::PaginationParams;

#[derive(Debug, Serialize, Deserialize)]
pub struct AuditLogFilter {
    pub action: Option<String>,
    pub entity_type: Option<String>,
    pub entity_id: Option<Uuid>,
    pub user_id: Option<Uuid>,
    pub start_date: Option<DateTime<Utc>>,
    pub end_date: Option<DateTime<Utc>>,
    pub ip_address: Option<String>,
}

#[derive(Debug, Serialize, sqlx::FromRow)]
pub struct AuditLogResponse {
    pub id: Uuid,
    pub user_id: Option<Uuid>,
    pub action: String,
    pub entity_type: Option<String>,
    pub entity_id: Option<Uuid>,
    pub old_values: Option<Value>,
    pub new_values: Option<Value>,
    pub ip_address: Option<String>, // Convertito da INET a String nella query
    pub user_agent: Option<String>,
    pub created_at: DateTime<Utc>,
}

#[derive(Debug, Serialize)]
pub struct AuditLogStats {
    pub total_logs: i64,
    pub actions_breakdown: Vec<ActionCount>,
    pub daily_activity: Vec<DailyActivity>,
    pub top_users: Vec<UserActivity>,
}

// FIXED: Tutti i campi count sono non-nullable
#[derive(Debug, Serialize, sqlx::FromRow)]
pub struct ActionCount {
    pub action: String,
    pub count: i64,
}

#[derive(Debug, Serialize, sqlx::FromRow)]
pub struct DailyActivity {
    pub date: chrono::NaiveDate,
    pub count: i64,
}

#[derive(Debug, Serialize, sqlx::FromRow)]
pub struct UserActivity {
    pub user_id: Uuid,
    pub username: String,
    pub count: i64,
}

#[derive(Serialize)]
pub struct ErrorResponse {
    error: String,
}

// Create audit log entry
pub async fn create_audit_log(
    Extension(pool): Extension<Arc<PgPool>>,
    claims: Claims,
    Json(log_data): Json<Value>,
) -> Result<StatusCode, (StatusCode, Json<ErrorResponse>)> {
    let user_id = claims.sub.parse::<Uuid>().map_err(|_| (
        StatusCode::BAD_REQUEST,
        Json(ErrorResponse {
            error: "Invalid user ID".to_string(),
        }),
    ))?;

    let action = log_data["action"].as_str().unwrap_or("unknown");
    let entity_type = log_data["entity_type"].as_str();
    let entity_id = log_data["entity_id"]
        .as_str()
        .and_then(|s| Uuid::parse_str(s).ok());
    let old_values = log_data.get("old_values");
    let new_values = log_data.get("new_values");
    
    // IP address handling
    let ip_address = log_data["ip_address"].as_str().map(|s| s.to_string());

    // FIXED: Cast esplicito a INET se il campo esiste
    sqlx::query!(
        r#"
        INSERT INTO audit_logs (user_id, action, entity_type, entity_id, old_values, new_values, ip_address)
        VALUES ($1, $2, $3, $4, $5, $6, $7::INET)
        "#,
        user_id,
        action,
        entity_type,
        entity_id,
        old_values,
        new_values,
        ip_address
    )
    .execute(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Failed to create audit log: {}", e),
        }),
    ))?;

    Ok(StatusCode::CREATED)
}

// Get audit logs with filtering and pagination
pub async fn get_audit_logs(
    Extension(pool): Extension<Arc<PgPool>>,
    _claims: Claims,
    Query(_filter): Query<AuditLogFilter>,
    Query(pagination): Query<PaginationParams>,
) -> Result<Json<Vec<AuditLogResponse>>, (StatusCode, Json<ErrorResponse>)> {
    let limit = pagination.limit.unwrap_or(50).min(1000); // Max 1000 records
    let offset = (pagination.page.unwrap_or(1) - 1) * limit;

    // FIXED: Cast ip_address::text per convertire INET a String
    let logs = sqlx::query_as!(
        AuditLogResponse,
        r#"
        SELECT id, user_id, action, entity_type, entity_id, 
               old_values, new_values, ip_address::text as ip_address, 
               user_agent, created_at
        FROM audit_logs
        ORDER BY created_at DESC
        LIMIT $1 OFFSET $2
        "#,
        limit,
        offset
    )
    .fetch_all(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Failed to fetch audit logs: {}", e),
        }),
    ))?;

    Ok(Json(logs))
}

// Get audit log by ID
pub async fn get_audit_log_by_id(
    Extension(pool): Extension<Arc<PgPool>>,
    _claims: Claims,
    Path(log_id): Path<Uuid>,
) -> Result<Json<AuditLogResponse>, (StatusCode, Json<ErrorResponse>)> {
    // FIXED: Cast ip_address::text per convertire INET a String
    let log = sqlx::query_as!(
        AuditLogResponse,
        r#"
        SELECT id, user_id, action, entity_type, entity_id,
               old_values, new_values, ip_address::text as ip_address, 
               user_agent, created_at
        FROM audit_logs
        WHERE id = $1
        "#,
        log_id
    )
    .fetch_optional(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Database error: {}", e),
        }),
    ))?
    .ok_or_else(|| (
        StatusCode::NOT_FOUND,
        Json(ErrorResponse {
            error: "Audit log not found".to_string(),
        }),
    ))?;

    Ok(Json(log))
}

// Get audit statistics
pub async fn get_audit_stats(
    Extension(pool): Extension<Arc<PgPool>>,
    _claims: Claims,
    Query(_filter): Query<AuditLogFilter>,
) -> Result<Json<AuditLogStats>, (StatusCode, Json<ErrorResponse>)> {
    // Total logs count
    let total_logs = sqlx::query_scalar!(
        "SELECT COUNT(*) FROM audit_logs"
    )
    .fetch_one(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Failed to count logs: {}", e),
        }),
    ))?
    .unwrap_or(0);

    // FIXED: Query con alias "count!" per campi non-nullable
    let actions_breakdown: Vec<ActionCount> = sqlx::query_as!(
        ActionCount,
        r#"
        SELECT action, COUNT(*)::bigint as "count!"
        FROM audit_logs
        GROUP BY action
        ORDER BY count DESC
        LIMIT 10
        "#
    )
    .fetch_all(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Failed to get actions breakdown: {}", e),
        }),
    ))?;

    // FIXED: Query con alias per campi non-nullable
    let daily_activity: Vec<DailyActivity> = sqlx::query_as!(
        DailyActivity,
        r#"
        SELECT DATE(created_at) as "date!", COUNT(*)::bigint as "count!"
        FROM audit_logs
        WHERE created_at >= NOW() - INTERVAL '30 days'
        GROUP BY DATE(created_at)
        ORDER BY date DESC
        "#
    )
    .fetch_all(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Failed to get daily activity: {}", e),
        }),
    ))?;

    // FIXED: Query con alias per campi non-nullable
    let top_users: Vec<UserActivity> = sqlx::query_as!(
        UserActivity,
        r#"
        SELECT al.user_id as "user_id!", u.username as "username!", 
               COUNT(*)::bigint as "count!"
        FROM audit_logs al
        JOIN users u ON al.user_id = u.id
        GROUP BY al.user_id, u.username
        ORDER BY count DESC
        LIMIT 10
        "#
    )
    .fetch_all(&*pool)
    .await
    .map_err(|e| (
        StatusCode::INTERNAL_SERVER_ERROR,
        Json(ErrorResponse {
            error: format!("Failed to get top users: {}", e),
        }),
    ))?;

    let stats = AuditLogStats {
        total_logs,
        actions_breakdown,
        daily_activity,
        top_users,
    };

    Ok(Json(stats))
}