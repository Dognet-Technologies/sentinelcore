// src/workers/epss_updater.rs
// EPSS (Exploit Prediction Scoring System) daily auto-update worker

use std::sync::Arc;
use tokio::time::{interval, Duration};
use sqlx::PgPool;
use tracing::{info, error};
use serde::{Deserialize, Serialize};
use std::io::BufRead;

/// Start EPSS auto-update worker
/// Downloads daily EPSS scores from FIRST.org (runs daily at midnight)
pub fn start_epss_updater(pool: Arc<PgPool>) {
    tokio::spawn(async move {
        let mut interval = interval(Duration::from_secs(86400)); // Every 24 hours

        info!("ðŸ“Š EPSS auto-update worker started (interval: 24 hours)");

        loop {
            interval.tick().await;

            info!("ðŸ“Š Downloading daily EPSS scores...");

            match update_epss_scores(&pool).await {
                Ok(count) => {
                    info!("âœ… Updated EPSS scores for {} CVEs", count);
                }
                Err(e) => {
                    error!("âŒ EPSS update failed: {}", e);
                }
            }
        }
    });
}

async fn update_epss_scores(pool: &PgPool) -> Result<i32, Box<dyn std::error::Error>> {
    info!("ðŸ“¥ Downloading EPSS CSV from FIRST.org...");

    // Download EPSS CSV from FIRST.org
    let url = "https://epss.cyentia.com/epss_scores-current.csv.gz";

    let client = reqwest::Client::new();
    let response = client
        .get(url)
        .header("User-Agent", "SentinelCore/1.0")
        .send()
        .await?;

    if !response.status().is_success() {
        return Err(format!("EPSS download error: {}", response.status()).into());
    }

    let bytes = response.bytes().await?;

    info!("ðŸ“¦ Decompressing EPSS data...");

    // Decompress gzip
    use flate2::read::GzDecoder;
    let decoder = GzDecoder::new(&bytes[..]);
    let reader = std::io::BufReader::new(decoder);

    let mut updated_count = 0;
    let mut batch_updates: Vec<(String, f32, f32)> = Vec::new();

    for (idx, line) in reader.lines().enumerate() {
        if idx == 0 {
            continue; // Skip header
        }

        let line = line?;
        let parts: Vec<&str> = line.split(',').collect();

        if parts.len() < 3 {
            continue;
        }

        let cve = parts[0].trim();
        let epss_score: f32 = parts[1].trim().parse().unwrap_or(0.0);
        let percentile: f32 = parts[2].trim().parse().unwrap_or(0.0);

        batch_updates.push((cve.to_string(), epss_score, percentile));

        // Batch update every 1000 records
        if batch_updates.len() >= 1000 {
            updated_count += update_batch(pool, &batch_updates).await?;
            batch_updates.clear();
        }
    }

    // Update remaining records
    if !batch_updates.is_empty() {
        updated_count += update_batch(pool, &batch_updates).await?;
    }

    // Mark update timestamp
    let _ = sqlx::query!(
        r#"
        INSERT INTO system_metadata (key, value)
        VALUES ('epss_last_update', NOW()::TEXT)
        ON CONFLICT (key) DO UPDATE SET value = NOW()::TEXT, updated_at = NOW()
        "#
    )
    .execute(pool)
    .await;

    Ok(updated_count)
}

async fn update_batch(
    pool: &PgPool,
    batch: &[(String, f32, f32)],
) -> Result<i32, Box<dyn std::error::Error>> {
    let mut count = 0;

    for (cve, epss_score, _percentile) in batch {
        let result = sqlx::query!(
            r#"
            UPDATE vulnerabilities
            SET epss_score = $2, epss_updated_at = NOW()
            WHERE cve_id = $1
            "#,
            cve,
            *epss_score
        )
        .execute(pool)
        .await?;

        count += result.rows_affected() as i32;
    }

    Ok(count)
}

// Simple system_metadata table (add to migrations if not exists)
// CREATE TABLE IF NOT EXISTS system_metadata (
//     key VARCHAR(255) PRIMARY KEY,
//     value TEXT,
//     created_at TIMESTAMPTZ DEFAULT NOW(),
//     updated_at TIMESTAMPTZ DEFAULT NOW()
// );
